---
title: "First Linear Predictions"
author: Corrie
date: "2020-04-22"
slug: chp4-part-two
layout: "single-projects"
categories:
  - R
  - Statistical Rethinking
tags: 
  - Statistical Rethinking
  - Bayesian 
comments: yes
image: 'images/tea_with_books.jpg'
share: yes
---

<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>


<p>These are code snippets and notes for the fourth chapter, <em>Geocentric Models</em>, , sections 4, of the book “Statistical Rethinking” (version 2) by Richard McElreath.</p>
<p>In this section, we work with our first prediction model where we use the weight to predict the height of a person. We again use the !Kung data and restrict to adults above 18.</p>
<pre class="r"><code>library(rethinking)
data(&quot;Howell1&quot;)
d &lt;- Howell1
d2 &lt;- d[ d$age &gt;= 18, ]
plot(height ~ weight, data=d2)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-1-1.svg" width="480" /></p>
<p>It looks like there is a nice, clear linear relationship between the weight and height of a person.</p>
<p>We use the following model to capture this relationship:
<span class="math display">\[\begin{align*}
h_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta(x_i - \bar{x}) \\
\alpha &amp;\sim \text{Normal}(178, 20) \\
\beta &amp;\sim \text{Normal}(0, 10) \\
\sigma &amp;\sim \text{Uniform}(0, 50)
\end{align*}\]</span></p>
<div id="prior-predictive-checks" class="section level3">
<h3>Prior Predictive Checks</h3>
<p>Before we start modelling this with R, let’s have a look at the priors and their implications for the model. For this, we’ll sample from the prior for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> and plot the resulting lines.</p>
<pre class="r"><code>set.seed(2971)
N &lt;- 100
a &lt;- rnorm( N, 178, 20 )
b &lt;- rnorm( N, 0, 10 )</code></pre>
<p>Let’s plot the lines resulting from these values:</p>
<p><img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-3-1.svg" width="480" /></p>
<p>This looks like a rather unreasonable model for height. There are many lines with a negative slope, meaning the heavier you are, the smaller you are. But even the lines with a positive slope have extremely steep slopes that seem rather unrealistic. Many lines go below the dashed line of zero height and above the line at 272cm representing the height of the tallest person.</p>
<p>Since we already know that the relationship between weight and height is positive, we can model the slope <span class="math inline">\(\beta\)</span> with a strictly positive distribution such as the log-normal:</p>
<pre class="r"><code>b &lt;- rlnorm( 1e4, 0 , 1 )
dens(b, xlim=c(0,5), adj=0.1)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-4-1.svg" width="384" /></p>
<p>Let’s plot the prior lines again, this time using the log-normal prior for <span class="math inline">\(\beta\)</span>:
<img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-5-1.svg" width="480" /></p>
<p>The log-normal prior for <span class="math inline">\(\beta\)</span> seems a much more reasonable choice for this model. Our new model then looks like this:
<span class="math display">\[\begin{align*}
h_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta(x_i - \bar{x}) \\
\alpha &amp;\sim \text{Normal}(178, 20) \\
\beta &amp;\sim \text{Log-Normal}(0, 10) \\
\sigma &amp;\sim \text{Uniform}(0, 50)
\end{align*}\]</span></p>
</div>
<div id="running-the-model-in-r" class="section level3">
<h3>Running the Model in R</h3>
<p>Now let’s translate the model to R, using <code>quap()</code> from the <code>{{rethinking}}</code> package:</p>
<pre class="r"><code>m4.3 &lt;- quap(
        alist(
          height ~ dnorm( mu, sigma),
          mu &lt;- a + b * ( weight - xbar ) ,
          a ~ dnorm( 156, 100),
          b ~ dlnorm( 0, 1),
          sigma ~ dunif(0, 50)
        ) ,
        data = d2
)</code></pre>
<p>The results:</p>
<pre class="r"><code>precis( m4.3 )</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
5.5%
</th>
<th style="text-align:right;">
94.5%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
a
</td>
<td style="text-align:right;">
154.60
</td>
<td style="text-align:right;">
0.27
</td>
<td style="text-align:right;">
154.17
</td>
<td style="text-align:right;">
155.03
</td>
</tr>
<tr>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.90
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.84
</td>
<td style="text-align:right;">
0.97
</td>
</tr>
<tr>
<td style="text-align:left;">
sigma
</td>
<td style="text-align:right;">
5.07
</td>
<td style="text-align:right;">
0.19
</td>
<td style="text-align:right;">
4.77
</td>
<td style="text-align:right;">
5.38
</td>
</tr>
</tbody>
</table>
<p>How do we interpret these values? So <span class="math inline">\(\alpha\)</span> is the (average) predicted height when $ x - {x} = 0$ that is, when <span class="math inline">\(x\)</span> is the mean height. So <span class="math inline">\(\alpha\)</span> is close to what we had for <span class="math inline">\(\mu\)</span> in our model without the linear part.
<span class="math inline">\(\beta\)</span> represents the increase in height if a person weighs one kg more.</p>
<p>We can check the covariances among the parameters:</p>
<pre class="r"><code>vcov( m4.3)</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
a
</th>
<th style="text-align:right;">
b
</th>
<th style="text-align:right;">
sigma
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
a
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.00
</td>
</tr>
<tr>
<td style="text-align:left;">
sigma
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.04
</td>
</tr>
</tbody>
</table>
<p>Or as a <code>pairs()</code> plot:</p>
<p><img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-11-1.svg" width="576" /></p>
<p>There is very little covariation between the parameters. This actually has to do with the fact that we centralized our predictor variable height.</p>
</div>
<div id="visualize-our-model" class="section level3">
<h3>Visualize our Model</h3>
<p>Let’s visualize the model to get a better understanding of its results. We start with plotting the raw data and the posterior mean of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> as a kind of “mean line” (or more officially, the MAP line):</p>
<p><img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-12-1.svg" width="480" /></p>
<p>This is a nice line but it does not visualize the uncertainty in the two parameters. One approach to visualize this uncertainty is to plot a few random lines sampled from the posterior, similarly to how we did for the prior predictive plots.</p>
<pre class="r"><code>post &lt;- extract.samples( m4.3 )
head(post)</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
a
</th>
<th style="text-align:right;">
b
</th>
<th style="text-align:right;">
sigma
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
155
</td>
<td style="text-align:right;">
0.94
</td>
<td style="text-align:right;">
5.22
</td>
</tr>
<tr>
<td style="text-align:right;">
154
</td>
<td style="text-align:right;">
0.89
</td>
<td style="text-align:right;">
4.75
</td>
</tr>
<tr>
<td style="text-align:right;">
154
</td>
<td style="text-align:right;">
0.92
</td>
<td style="text-align:right;">
5.34
</td>
</tr>
<tr>
<td style="text-align:right;">
154
</td>
<td style="text-align:right;">
0.92
</td>
<td style="text-align:right;">
5.16
</td>
</tr>
</tbody>
</table>
<p>To be able to better see the difference in uncertainty, we refit the model again on a subset of the data. This way, we can observe how the uncertainty decreases when we add more data:
<img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-15-1.svg" width="672" /></p>
<p>How do we compute compatibility intervals? For a single weight value, say 50 kilograms, proceed as follows:</p>
<pre class="r"><code>post &lt;- extract.samples(m4.3)
mu_at_50 &lt;- post$a + post$b * ( 50 - xbar )</code></pre>
<pre class="r"><code>dens( mu_at_50, col=rangi2, lwd=2, xlab=&quot;mu | weight=50&quot;)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-17-1.svg" width="480" /></p>
<pre class="r"><code>PI(mu_at_50, prob=0.89)</code></pre>
<pre><code> 5% 94% 
159 160 </code></pre>
<p>Using the <code>link()</code> function, we can compute the distribution of <span class="math inline">\(\mu\)</span> for each value of observed weight.</p>
<pre class="r"><code>mu &lt;- link(m4.3)
str(mu)</code></pre>
<pre><code> num [1:1000, 1:352] 157 158 158 158 157 ...</code></pre>
<p>Instead of computing the <span class="math inline">\(\mu\)</span>-values for the observed weight values, we can provide new data, e.g. all weight values in the range of reasonable weight values:</p>
<pre class="r"><code>weight.seq &lt;- seq( from=25, to=70, by=1)

mu &lt;- link(m4.3, data = data.frame( weight=weight.seq ) )
str(mu)</code></pre>
<pre><code> num [1:1000, 1:46] 138 136 137 137 135 ...</code></pre>
<p>We can plot all 1000 x 146 values for <span class="math inline">\(\mu\)</span>:</p>
<pre class="r"><code>plot(height ~ weight, d2, type=&quot;n&quot;)

for (i in 1:100)
  points(weight.seq, mu[i,], pch=16, col=col.alpha(rangi2, 0.1))</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-20-1.svg" width="480" /></p>
<p>Or we can summarize the values for each weight and compute the mean and a compatibility interval:</p>
<pre class="r"><code>mu.mean &lt;- apply(mu, 2, mean)
mu.PI &lt;- apply(mu, 2, PI, prob=0.89)</code></pre>
<pre class="r"><code># plot raw data
plot(height ~ weight, data=d2, col=col.alpha(rangi2, 0.5))

# plot the MAP line
lines(weight.seq, mu.mean)

# plot a shaded region for 89% PI
shade( mu.PI, weight.seq)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-22-1.svg" width="480" /></p>
</div>
<div id="all-the-uncertainty" class="section level3">
<h3>All the Uncertainty</h3>
<p>So far, we’ve only worked with <span class="math inline">\(\mu\)</span> and its uncertainty. If we want to generate new observations (i.e. predictions) we also have to account for the uncertainty in the standard deviation <span class="math inline">\(\sigma\)</span>. To simulate new heights, we pluck the values for <span class="math inline">\(\mu\)</span> together with the values for <span class="math inline">\(\sigma\)</span> into a normal distribution. Or simply use the function <code>sim()</code>:</p>
<pre class="r"><code>sim.height &lt;- sim( m4.3, data=list(weight=weight.seq))
str(sim.height)</code></pre>
<pre><code> num [1:1000, 1:46] 130 130 133 146 144 ...</code></pre>
<p>For each weight, we can then get a compatibility interval of predicted heights:</p>
<pre class="r"><code>height.PI &lt;- apply(sim.height, 2, PI, prob=0.89)
height.PI[,1:5]</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;">
5%
</td>
<td style="text-align:right;">
128
</td>
<td style="text-align:right;">
129
</td>
<td style="text-align:right;">
130
</td>
<td style="text-align:right;">
132
</td>
<td style="text-align:right;">
132
</td>
</tr>
<tr>
<td style="text-align:left;">
94%
</td>
<td style="text-align:right;">
144
</td>
<td style="text-align:right;">
146
</td>
<td style="text-align:right;">
147
</td>
<td style="text-align:right;">
148
</td>
<td style="text-align:right;">
149
</td>
</tr>
</tbody>
</table>
<p>And visualize both the uncertainty in <span class="math inline">\(\mu\)</span> and the uncertainty in the prediction:</p>
<pre class="r"><code># plot everything together
plot( height ~ weight, d2, col=col.alpha(rangi2, 0.5))

# draw a MAP line
lines(weight.seq, mu.mean)

# draw PI region for line
shade(mu.PI, weight.seq)

# draw PI region for simulated heights
shade(height.PI, weight.seq )</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-26-1.svg" width="480" /></p>
<p>Our model suggests that 89% of observed data points should be within these boundaries.
We can also visualize different boundaries:
<img src="/projects/Statistical-Rethinking/Chapter_4/chapter4b_files/figure-html/unnamed-chunk-27-1.svg" width="672" /></p>
<p>We could also simulate the heights manually. Remember, to manually compute <span class="math inline">\(\mu\)</span> (instead of using <code>link()</code>), we use the following:</p>
<pre class="r"><code>post &lt;- extract.samples(m4.3)
weight.seq &lt;- 25:70
mu &lt;- sapply(weight.seq, function(weight) post$a + post$b * ( weight - xbar ) )</code></pre>
<p>To generate height observations, we also compute <span class="math inline">\(\mu\)</span> but pluck it straight into the normal distribution <code>rnorm()</code> to sample from it:</p>
<pre class="r"><code>sim.height &lt;- sapply( weight.seq, function(weight)
  rnorm(
    n=nrow(post),
    mean=post$a + post$b * ( weight - xbar ),
    sd=post$sigma
  ))</code></pre>
<p><small><a href="https://github.com/corriebar/Statistical-Rethinking/blob/master/Chapter_4/chapter4b.Rmd">Full code.</a><small></p>
</div>
