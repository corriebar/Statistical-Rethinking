---
title: "Markov Chain Monte Carlo"
author: "Corrie"
date: "September 4, 2018"
output: 
  github_document:
    pandoc_args: --webtex 
---



<div id="king-markov-and-his-island-kingdom" class="section level2">
<h2>8.1 King Markov and His island kingdom</h2>
<p>A simple example of the Markov Chain Monte Carlo algorithm:</p>
<pre class="r"><code>num_weeks &lt;- 1e5
positions &lt;- rep(0, num_weeks)
current &lt;- 10
for (i in 1:num_weeks) {
  # record current position
  positions[i] &lt;- current
  
  # flip coin to generate proposal
  proposal &lt;- current + sample( c(-1, 1), size=1)
  if ( proposal &lt; 1 ) proposal &lt;- 10
  if ( proposal &gt; 10 ) proposal &lt;- 1
  
  # move?
  prob_move &lt;- proposal / current
  current &lt;- ifelse( runif(1) &lt; prob_move , proposal, current)
}</code></pre>
<pre class="r"><code>par(mfrow=c(1,2))
plot( (1:100), positions[1:100], xlab=&quot;week&quot;, ylab=&quot;island&quot;, col=&quot;midnightblue&quot;)
plot(table(positions), col=&quot;midnightblue&quot;, xlab=&quot;island&quot;, ylab=&quot;number of weeks&quot;)</code></pre>
</div>
<div id="easy-hmc-map2stan" class="section level2">
<h2>8.3 Easy HMC: <code>map2stan</code></h2>
<p>Using the terrain ruggedness data from Chapter 7:</p>
<pre class="r"><code>library(rethinking)
data(rugged)
d &lt;- rugged
d$log_gdp &lt;- log(d$rgdppc_2000)
dd &lt;- d[ complete.cases(d$rgdppc_2000), ]</code></pre>
<p>Fitting the old way using <code>map</code>:</p>
<pre class="r"><code>m8.1 &lt;- map(
  alist(
    log_gdp ~ dnorm( mu, sigma ),
    mu &lt;- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
    a ~ dnorm( 0, 100),
    bR ~ dnorm(0, 10),
    bA ~ dnorm(0 , 10),
    bAR ~ dnorm(0, 10),
    sigma ~ dunif(0, 10)
  ),
  data = dd
)
precis(m8.1)</code></pre>
<p>To use Stan, we should do some preprocessing. In particular, preprocess all variable transformations and make a trimmed data frame, only containing the variables used in the model.</p>
<pre class="r"><code>dd.trim &lt;- dd[ , c(&quot;log_gdp&quot;, &quot;rugged&quot;, &quot;cont_africa&quot;)]
str(dd.trim)</code></pre>
<p>Using Stan:</p>
<pre class="r"><code>m8.1stan &lt;- map2stan(
  alist(
    log_gdp ~ dnorm( mu, sigma) ,
    mu &lt;- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa,
    a ~ dnorm(0, 100),
    bR ~ dnorm(0, 10),
    bA ~ dnorm(0, 10),
    bAR ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 2)
  ), 
  data=dd.trim,
  start=list(a=5, bR=0, bA=0, bAR=0, sigma=1)
)</code></pre>
<pre class="r"><code>precis(m8.1stan)</code></pre>
<p>It is possible to draw more samples from the stan model, also using more chains:</p>
<pre class="r"><code>m8.1stan_4chains &lt;- map2stan( m8.1stan, chains=4, cores=4)
precis(m8.1stan_4chains)</code></pre>
<p>To visualize the results, you can plot the samples. To pull out samples, use</p>
<pre class="r"><code>post &lt;- extract.samples( m8.1stan )
str(post)</code></pre>
<pre class="r"><code>pairs(post)</code></pre>
<p>A prettier plot is also available, directly on the stan model:</p>
<pre class="r"><code>pairs( m8.1stan )</code></pre>
<p>By default, <code>map2stan</code> computes DIC and WAIC. We can extract them with</p>
<pre class="r"><code>DIC(m8.1stan)</code></pre>
<p>and</p>
<pre class="r"><code>WAIC(m8.1stan)</code></pre>
<p>Alternatively, it is also displayed in the default <code>show</code> output:</p>
<pre class="r"><code>show(m8.1stan)</code></pre>
<p>To get the trace plots of the Markov Chain:</p>
<pre class="r"><code>plot( m8.1stan, window=c(100,2000), col=&quot;royalblue4&quot;, n_cols=2)</code></pre>
<p>To get a glimpse at the raw stan code, we can use <code>stancode()</code></p>
<pre class="r"><code>stancode(m8.1stan)</code></pre>
</div>
<div id="care-and-feeding-of-your-markov-chain" class="section level2">
<h2>8.4 Care and feeding of your Markov chain</h2>
<p>Example of non-convergent chain:</p>
<pre class="r"><code>y &lt;- c(-1, 1)
m8.2 &lt;- map2stan(
  alist(
    y ~ dnorm( mu, sigma),
    mu &lt;- alpha
  ),
  data=list(y=y), start=list(alpha=0, sigma=1),
  chains=2, iter=4000, warmup=1000
)</code></pre>
<p>There are quite a few warnings on divergencies. Let’s have a look at the estimates:</p>
<pre class="r"><code>precis(m8.2)</code></pre>
<p>This doesn’t look right: The estimates are a very far way out there, the effective number of samples is relatively low and <code>Rhat</code> is above 1. While <code>Rhat</code> in my case is only around 1.01, even such a value is already suspicious. Let’s have a look at the trace plots.</p>
<pre class="r"><code>plot(m8.2, col=c(&quot;black&quot;, &quot;royalblue4&quot;), n_cols=1)</code></pre>
<p>The problem: The priors are very flat which means that even values of 500 millions are plausible values.
We can fix this by adding a weakly informative prior:</p>
<pre class="r"><code>m8.3 &lt;- map2stan(
  alist(
    y ~ dnorm( mu, sigma),
    mu &lt;- alpha,
    alpha ~ dnorm(1, 10),
    sigma ~ dcauchy( 0, 1)
  ),
  data=list(y=y), start=list(alpha=0, sigma=1),
  chains=2, iter=4000, warmup=1000
)
precis(m8.3)</code></pre>
<p>The estimates seem much more reasonable and the <code>Rhat</code> value is now 1.</p>
<pre class="r"><code>plot(m8.3, col=c(&quot;black&quot;, &quot;royalblue4&quot;), n_cols=1)</code></pre>
<p>The chains also look good now.</p>
<p>If we compare the prior and posterior distribution, even two points can overcome these weakly informative priors and thus lead to better results than flat priors.</p>
<pre class="r"><code>post &lt;- extract.samples(m8.3)
par(mfrow=c(1, 2))
sq &lt;- seq(-15, 20, length.out = 100)
plot( density(post$alpha,  from=-15, to=20, adj=1),
      lwd=2, col=&quot;royalblue4&quot;, xlab=&quot;alpha&quot;, 
     main=&quot;&quot;)
points(sq, dnorm(sq, 1, 10), type=&quot;l&quot;, lty=2)
text(4.5, 0.3, labels = &quot;Posterior&quot;)
text(8, 0.06, labels=&quot;Prior&quot;)

sq &lt;- seq(0, 10, length.out = 100)
plot( density( post$sigma, from=0, to=10, adj=1.5),
      lwd=2, col=&quot;royalblue4&quot;, xlab=&quot;sigma&quot;, 
      main=&quot;&quot;)
points(sq, 2*dcauchy(sq, 0, 1), type=&quot;l&quot;, lty=2)</code></pre>
<div id="non-identifiable-parameters" class="section level3">
<h3>Non-identifiable parameters</h3>
<p>We’ve learned before how highly correlated predictors lead to non-identifiable parameters. Let’s have a look how these look inside a Markov chain.</p>
<pre class="r"><code>y &lt;- rnorm( 100, mean=0, sd=1 )</code></pre>
<p>We fit the following unidentifiable model:</p>
<pre class="r"><code>m8.4 &lt;- map2stan(
  alist(
    y ~ dnorm( mu, sigma),
    mu &lt;- a1 + a2,
    sigma ~ dcauchy( 0, 1)
  ), 
  data=list(y=y), start=list(a1=0, a2=0, sigma=1),
  chains=2, iter=4000, warmup=1000
)
precis(m8.4)</code></pre>
<p>These estimates of <code>a1</code> and <code>a2</code> look suspicious. Also, <code>n_eff</code> and <code>Rhat</code> have terrible values.</p>
<pre class="r"><code>plot(m8.4, col=c(&quot;black&quot;, &quot;royalblue4&quot;), n_cols=1)</code></pre>
<p>The trace plots also don’t look good: The two chains are not mixing and are definitely not stationary.
Again, we can use weak priors to solve this problem:</p>
<pre class="r"><code>m8.5 &lt;- map2stan(
  alist(
    y ~ dnorm( mu, sigma),
    mu &lt;- a1 + a2,
    a1 ~ dnorm(0, 10),
    a2 ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 1)
  ),
  data=list(y=y), start=list(a1=0, a2=0, sigma=1),
  chains=2, iter=4000, warmup=1000
)
precis(m8.5)</code></pre>
<p>Not only did the model sample much faster, both the estimates and the values for <code>n_eff</code> and <code>Rhat</code> look much better.</p>
<pre class="r"><code>plot(m8.5, col=c(&quot;black&quot;, &quot;royalblue4&quot;), n_cols=1)</code></pre>
<p>The trace plots as well look very good: stationary and well mixed.</p>
</div>
<div id="overthinking-cauchy-distribution" class="section level3">
<h3>Overthinking: Cauchy distribution</h3>
<p>The Cauchy distribution does not have mean since it has a very thick-tailed distribution.
At any moment in a Cauchy sampling process, a very high value can be drawn that overwhelms all of the previous draw and hence the the distribution does not converge to a mean.</p>
<pre class="r"><code>set.seed(13)
y &lt;- rcauchy(1e4, 0, 5)
mu &lt;- sapply(1:length(y), function(i) sum(y[1:i]/i))
plot(mu, type=&quot;l&quot;)</code></pre>
</div>
</div>
