---
title: "Of Monsters and Mixtures"
author: Corrie
date: "2019-04-14"
slug: chp12-part-one
layout: "single-projects"
categories:
  - R
  - Statistical Rethinking
tags: 
  - Statistical Rethinking
  - Bayesian 
comments: yes
image: 'images/tea_with_books.jpg'
share: yes
---



<div id="over-dispersed-outcomes" class="section level2">
<h2>Over-dispersed outcomes</h2>
<p>For the beta-binomial model, we’ll make use of the beta distribution. The beta distribution is a probability distribution over probabilities (over the interval <span class="math inline">\([0, 1]\)</span>).</p>
<pre class="r"><code>library(rethinking)
pbar &lt;- 0.5
theta &lt;- 5
curve( dbeta2( x, pbar, theta), from=0, to=1, xlab=&quot;probability&quot;, ylab=&quot;Density&quot;)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>There are different ways to parametrize the beta distribution:</p>
<pre class="r"><code>dbeta2 &lt;- function( x , prob , theta , log=FALSE ) {
    a &lt;- prob * theta
    b &lt;- (1-prob) * theta
    dbeta( x , shape1=a , shape2=b , log=log )
}</code></pre>
<p>We use the beta-binomial for the <code>UCBadmit</code> data, which is over-dispersed if we ignore department (since the admission rate varied quite a lot for different departments).
Our model looks as follows:
<span class="math display">\[\begin{align*}
A_i &amp;\sim \text{BetaBinomial}(N_i, \bar{p}_i, \theta) \\
\text{logit}(\bar{p}_i) &amp;= \alpha_{\text{GID}[i]}) \\
\alpha_j &amp;\sim \text{Normal}(0, 1.5) \\
\theta &amp;\sim \text{Exponential}(1)
\end{align*}\]</span>
where <span class="math inline">\(A\)</span> is <code>admit</code>, <span class="math inline">\(N\)</span> is the number of applications <code>applications</code>, and GID<span class="math inline">\([i]\)</span> is gender id, 1 for male and 2 for female.</p>
<pre class="r"><code>data(&quot;UCBadmit&quot;)
d &lt;- UCBadmit
d$gid &lt;- ifelse(d$applicant.gender == &quot;male&quot;, 1L, 2L)
dat &lt;- list(A = d$admit, N = d$applications, gid=d$gid)

m12.1 &lt;- ulam(
  alist(
    A ~ dbetabinom( N, pbar, theta),
    logit(pbar) &lt;- a[gid],
    a[gid] ~ dnorm(0, 1.5),
    theta ~ dexp(1)
  ), data=dat, chains=4
)</code></pre>
<pre class="r"><code>post &lt;- extract.samples(m12.1 )
post$da &lt;- post$a[,1] - post$a[,2]
precis( post, depth=2)</code></pre>
<pre><code>            mean        sd       5.5%     94.5%  histogram
a[1]  -0.4170432 0.4327273 -1.1055429 0.2583752    ▁▂▇▇▂▁▁
a[2]  -0.3063994 0.4285321 -0.9805098 0.4067581    ▁▁▅▇▃▁▁
theta  2.6763961 0.9493179  1.3789576 4.2942542  ▁▃▇▃▁▁▁▁▁
da    -0.1106438 0.5862838 -1.0271344 0.8384815 ▁▁▁▃▇▇▂▁▁▁</code></pre>
<p><code>a[1]</code> is the log-odds of admission for male applicants which is lower than <code>a[2]</code>, the log-odds for female applicants. This might suggest there is a diffenrece in admission rates by gender, but the posterior difference <code>da</code> is highly uncertain with probability mass both above and below zero.</p>
<p>We can visualize the posterior Beta-distribution:</p>
<pre class="r"><code>gid &lt;- 2
# draw posterior mean beta distribution
curve( dbeta2(x, mean( logistic(post$a[, gid])), mean(post$theta)), from=0, to=1,
       ylab=&quot;Density&quot;, xlab=&quot;probability admit&quot;, ylim=c(0,3), lwd=2)

# draw 50 beta distributions sampled from posterior
for ( i in 1:50 ) {
  p &lt;- logistic( post$a[i, gid ] )
  theta &lt;- post$theta[i]
  curve( dbeta2(x, p, theta), add=T,col=col.alpha(&quot;black&quot;, 0.2))
}
mtext(&quot;distribution of female admission rates&quot;)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>There is a tendency for admission rates below 40% but the most plausible (the mean Beta-distribution) also allows for very high admission rates above 80%. This way, the model incorporated the high variation among departments.</p>
<pre class="r"><code>postcheck(m12.1)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The prediction intervals are very wide, the model incorporated such a wide variance since even though it doesn’t see the different departments, it does see heterogeneity across rows.</p>
</div>
<div id="negative-binomial" class="section level2">
<h2>Negative-Binomial</h2>
<p>Similar as with the Beta-Binomial, we can fit a Poisson model, where each observation has its own rate. The rate comes from a common gamma distribution.</p>
<pre class="r"><code>phi &lt;- 2
lambda &lt;- 1
curve( dgamma( x, shape=phi, rate=lambda), from=0, to=20, xlab=&quot;rate&quot;, ylab=&quot;probability density&quot;)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>We check again the Kline data of the tool counts for different islands, this time using the negative-binomial model.</p>
<pre class="r"><code>data(Kline)
d &lt;- Kline
d$P &lt;- standardize( log( d$population ) )
d$contact_id &lt;- ifelse( d$contact == &quot;high&quot;, 2L, 1L)

dat2 &lt;- list(
  TT = d$total_tools,
  P = d$population,
  cid = d$contact_id
)

m12.3 &lt;- ulam(
  alist(
    TT ~ dgampois( lambda, phi ),
    lambda &lt;- exp( a[cid])*P^b[cid] / g,
    a[cid] ~ dnorm(1, 1),
    b[cid] ~ dexp(1),
    g ~ dexp(1),
    phi ~ dexp(1)
  ), data=dat2, chains=4, log_lik = TRUE
)</code></pre>
<p>For comparison, we also fit our model from before, using a pure Poisson model.</p>
<pre class="r"><code>m11.11 &lt;- ulam(
  alist(
    TT ~ dpois(lambda),
    lambda &lt;- exp( a[cid] )*P^b[cid] / g,
    a[cid] ~ dnorm(1,1),
    b[cid] ~ dexp(1),
    g ~ dexp(1)
  ), data=dat2, chains=4, log_lik = T
)</code></pre>
<pre class="r"><code>k &lt;- PSIS( m11.11 , pointwise=TRUE )$k
par(bty=&quot;l&quot;, mfrow=c(1,2))
plot( d$population, d$total_tools, xlab=&quot;population&quot;, ylab=&quot;total tools&quot;,
      col=rangi2, pch=ifelse(dat2$cid == 1, 1, 16), lwd=2,
      ylim=c(0,74), cex=1+normalize(k) )

ns &lt;- 100
P_seq &lt;- seq(from=0, to=12.55, length.out = ns)
pop_seq &lt;- exp( P_seq )

lambda &lt;- link(m12.3, data=data.frame(P = pop_seq, cid=1))
lmu &lt;- apply(lambda, 2, mean)
lci &lt;- apply(lambda, 2, PI )
lci2 &lt;- ifelse(lci &gt;= 74, 74, lci)
lines( pop_seq, ifelse(lmu&gt;=74, NA, lmu), lty=2, lwd=1.5)
shade(lci2, pop_seq, xpd=TRUE)

lambda &lt;- link(m12.3, data=data.frame(P = pop_seq, cid=2))
lmu &lt;- apply(lambda, 2, mean)
lci &lt;- apply(lambda, 2, PI )
lci2 &lt;- ifelse(lci &gt;= 74, 74, lci)
lines( pop_seq, ifelse(lmu&gt;=74, NA, lmu), lty=1, lwd=1.5)
shade(lci2, pop_seq, xpd=TRUE)
text(c(9e4, 1e5), c(68, 50), labels=c(&quot;high contact&quot;, &quot;low contact&quot;))
mtext(&quot;gamma-Poisson model&quot;)


plot( d$population, d$total_tools, xlab=&quot;population&quot;, ylab=&quot;total tools&quot;,
      col=rangi2, pch=ifelse(dat2$cid == 1, 1, 16), lwd=2,
      ylim=c(0,74), cex=1+normalize(k) )

lambda &lt;- link(m11.11, data=data.frame(P = pop_seq, cid=1))
lmu &lt;- apply(lambda, 2, mean)
lci &lt;- apply(lambda, 2, PI )
lci2 &lt;- ifelse(lci &gt;= 74, 74, lci)
lines( pop_seq, ifelse(lmu&gt;=74, NA, lmu), lty=2, lwd=1.5)
shade(lci2, pop_seq, xpd=TRUE)

lambda &lt;- link(m11.11, data=data.frame(P = pop_seq, cid=2))
lmu &lt;- apply(lambda, 2, mean)
lci &lt;- apply(lambda, 2, PI )
lci2 &lt;- ifelse(lci &gt;= 74, 74, lci)
lines( pop_seq, ifelse(lmu&gt;=74, NA, lmu), lty=1, lwd=1.5)
shade(lci2, pop_seq, xpd=TRUE)
mtext(&quot;pure Poisson model&quot;)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-10-1.png" width="1056" /></p>
<p>Again, we can see that the mixture model incorporates much more uncertainty compared to the pure, non-mixed model.</p>
</div>
<div id="zero-inflated-outcomes" class="section level2">
<h2>Zero-inflated outcomes</h2>
<p>Often, the things we measure are not from any pure process but rather mixtures of different processes. One such example is count data. Very often a count of zero can happen in more than one way: either the rate of processes is low or the process that generates events failed to start in the first place.</p>
<p>If we go back to our example of monks writing manuscripts. Many monks work on manuscripts and on some days, they’ll finish a few. The rate is thus very low and there will be days where no manuscript is finished. However, imagine that on some days, the monks take a break and instead of writing, they open the wine cellar. On these days, no manuscript will be produced. So we have two ways how we end up with a count of no manuscripts.</p>
<p>Let’s simulate this process.
We assume that the probability on any day that the monks are drinking instead of working is 20%. The rate at which they produce manuscripts is one manuscript per day.</p>
<pre class="r"><code>prob_drink &lt;- 0.2
rate_work &lt;- 1</code></pre>
<p>We simulate counts for one whole year. First, for each day we simulate using a binomial process, if the monks were drinking or working.</p>
<pre class="r"><code>N &lt;- 365
set.seed(365)
drink &lt;- rbinom( N, 1, prob_drink)</code></pre>
<p>Next, for each day we simulate how many manuscripts the monks would have finished and multiply with 0 if on a day the monks were drinking.</p>
<pre class="r"><code>y &lt;- (1-drink)*rpois(N, rate_work)</code></pre>
<p>Let’s visualize the simulated data:</p>
<pre class="r"><code>simplehist( y, xlab=&quot;manuscripts completed&quot;, lwd=4)
zeros_drink &lt;- sum(drink)
zeros_work &lt;- sum(y==0 &amp; drink == 0)
zeros_total &lt;- sum(y==0)
lines(c(0,0), c(zeros_work, zeros_total), lwd=4, col=rangi2 )</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>The blue part signifies the days were no manuscripts were completed because the monks were drinking. The total number of zeros is inflated, relative to a typical Poisson distribution.</p>
<p>To fit this Zero-Inflated Poisson model, we can use the function <code>dzipois()</code> provided in the Rethinking-package.
The prior for the probability of drinking is nudged so that there is more mass below 0.5, the monks probably don’t drink more often than not:</p>
<pre class="r"><code>ap &lt;- rnorm(1000, -1.5, 1)
p &lt;- inv_logit(ap)
dens(p)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_12/chapter12a_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>The model then looks as follows:</p>
<pre class="r"><code>m12.4 &lt;- ulam(
  alist(
    y ~ dzipois( p, lambda ),
    # p = probability monks are drinking
    logit(p) &lt;- ap,
    # lambda = rate for completing manuscripts
    log(lambda) &lt;- al,
    ap ~ dnorm( -1.5, 1 ),
    al ~ dnorm( 1, 0.5 )
  ), data=list(y=as.integer(y)), chains=4)</code></pre>
<pre class="r"><code>precis(m12.4)</code></pre>
<pre><code>          mean         sd       5.5%      94.5%    n_eff    Rhat4
ap -1.27943087 0.37228853 -1.9347033 -0.7735818 584.0565 1.003241
al  0.01190568 0.09243819 -0.1376475  0.1624185 649.3856 1.009246</code></pre>
<p>On the natural scale, those estimates are:</p>
<pre class="r"><code>inv_logit(-1.28)</code></pre>
<pre><code>[1] 0.2175502</code></pre>
<pre class="r"><code>exp(0.01)</code></pre>
<pre><code>[1] 1.01005</code></pre>
<p>Note that we get a very good estimate of the proportion of days the monks drink, even though we can’t say for any particular day whether or not they drank.</p>
<p>The function <code>dzipois()</code> already does most of the work for us, but let’s check how such a model is implemented:</p>
<pre class="r"><code>m12.4_alt &lt;- ulam(
  alist(
    # log-lkhd for non-zero values: (1-p)=prob of not drinking
    # poisson_lpmf = probability of finishing y manuscripts
    y|y&gt;0 ~ custom( log( 1-p ) + poisson_lpmf(y|lambda ) ),
    # log-lkhd for zero values: p=prob of drinking
    # (1-p)*exp(lambda) = prob of finishing zero manuscripts when not drinking
    y|y==0 ~ custom( log( p + (1-p)*exp(lambda ) )),
    logit(p) &lt;- ap,
    log(lambda) &lt;- al,
    ap ~ dnorm(-1.5, 1),
    al ~ dnorm(1, 0.5)
  ), data=list(y=as.integer(y)), chains=4
)</code></pre>
<p>However, for numerical stability, it is better to use the functions <code>log1m(p)</code> for <code>log(1-p)</code> and <code>log_mix(p, 0, poisson_lpmf(0|lambda))</code> instead of <code>log(p + (1-p)*exp(lambda))</code>.</p>
<pre class="r"><code>m12.4_alt &lt;- ulam(
  alist(
    # log-lkhd for non-zero values: (1-p)=prob of not drinking
    # poisson_lpmf = probability of finishing y manuscripts
    y|y&gt;0 ~ custom( log1m( p ) + poisson_lpmf(y|lambda ) ),
    # log-lkhd for zero values: p=prob of drinking
    # (1-p)*exp(lambda) = prob of finishing zero manuscripts when not drinking
    y|y==0 ~ custom( log_mix( p, 0, poisson_lpmf(0|lambda) ) ),
    logit(p) &lt;- ap,
    log(lambda) &lt;- al,
    ap ~ dnorm(-1.5, 1),
    al ~ dnorm(1, 0.5)
  ), data=list(y=as.integer(y)), chains=4
)</code></pre>
<p>This gives us the same estimates as <code>m12.4</code>:</p>
<pre class="r"><code>precis(m12.4_alt)</code></pre>
<pre><code>          mean         sd       5.5%      94.5%    n_eff     Rhat4
ap -1.26899142 0.34561667 -1.8757107 -0.8064936 605.9883 1.0004240
al  0.01130696 0.08613438 -0.1257928  0.1483133 601.1485 0.9994628</code></pre>
<p>It’s also helps to look at the stan code of the model:</p>
<pre class="r"><code>stancode(m12.4_alt)</code></pre>
<pre><code>data{
    int y[365];
}
parameters{
    real ap;
    real al;
}
model{
    real p;
    real lambda;
    al ~ normal( 1 , 0.5 );
    ap ~ normal( -1.5 , 1 );
    lambda = al;
    lambda = exp(lambda);
    p = ap;
    p = inv_logit(p);
    for ( i in 1:365 ) 
        if ( y[i] == 0 ) target += log_mix(p, 0, poisson_lpmf(0 | lambda));
    for ( i in 1:365 ) 
        if ( y[i] &gt; 0 ) target += log1m(p) + poisson_lpmf(y[i] | lambda);
}</code></pre>
<p>The most important of the model is in the <code>for</code> loop, iterating over each observation. It adds the log-likelihood to the variable <code>target</code> which is the log posterior mass. The suffix <code>_lpmf</code> means it’s the log probability mass function. (For continuous variables the suffix would be <code>_lpdf</code>, log probability density function).</p>
</div>
