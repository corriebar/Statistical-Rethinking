---
title: "Binomial Regression"
author: "Corrie"
date: "October 4, 2018"
output: 
  html_document:
    toc: true
    toc_float: true
  github_document:
    pandoc_args: --webtex 
---



<div id="logistic-regression" class="section level2">
<h2>Logistic Regression</h2>
<p>The chimpanzee data: Do chimpanzee pick the more social option?</p>
<pre class="r"><code>library(rethinking)
data(chimpanzees)
d &lt;- chimpanzees</code></pre>
<p>The important variables are the variable <code>condition</code>, indicating if another chimpanzee sits opposite (1) the table or not (0) and the variable <code>prosocial_left</code> which indicates if the left lever is the more social option. These two variables will be used to predict if the chimpanzees pull the left lever or not (<code>pulled_left</code>).</p>
<p>The implied model is:
<span class="math display">\[\begin{align*}
L_i &amp;\sim \text{Binomial}(1, p_i)\\
\text{logit}(p_i) &amp;= \alpha + (\beta_P + \beta_{PC}C_i)P_i \\
\alpha &amp;\sim \text{Normal}(0, 10) \\
\beta_P &amp;\sim \text{Normal}(0, 10) \\
\beta_{PC} &amp;\sim \text{Normal}(0, 10) 
\end{align*}\]</span></p>
<p>We’ll write this as a <code>map()</code> model but will start with two simpler models with less predictors, starting with one model that has only an intercept and no predictor variables:</p>
<pre class="r"><code>m10.1 &lt;- map(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) &lt;- a,
    a ~ dnorm(0, 10)
  ),
  data=d
)
precis(m10.1)</code></pre>
<pre><code>       mean         sd     5.5%     94.5%
a 0.3201415 0.09022718 0.175941 0.4643419</code></pre>
<p>This implies a MAP probability of pulling the left lever of</p>
<pre class="r"><code>logistic(0.32)</code></pre>
<pre><code>[1] 0.5793243</code></pre>
<p>with a 89% interval of</p>
<pre class="r"><code>logistic( c(0.18, 0.46))</code></pre>
<pre><code>[1] 0.5448789 0.6130142</code></pre>
<p>Next the models using the predictors:</p>
<pre class="r"><code>m10.2 &lt;- map(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) &lt;- a + bp*prosoc_left,
    a ~ dnorm(0, 10),
    bp ~ dnorm(0, 10)
  ),
  data=d
)
m10.3 &lt;- map(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) &lt;- a + (bp + bpC*condition)*prosoc_left,
    a ~ dnorm(0, 10),
    bp ~ dnorm(0, 10),
    bpC ~ dnorm(0, 10)
  ),
  data=d
)

(cp &lt;- compare(m10.1, m10.2, m10.3) )</code></pre>
<pre><code>          WAIC       SE    dWAIC       dSE    pWAIC     weight
m10.2 680.5384 9.253663 0.000000        NA 2.020256 0.70166499
m10.3 682.3666 9.330073 1.828221 0.9156754 3.009858 0.28127863
m10.1 687.9722 7.105368 7.433864 6.1334050 1.016019 0.01705637</code></pre>
<p>The model without the interaction seems to fare better even though the third model best reflects the structure of the experiment.</p>
<pre class="r"><code>plot( cp )#, </code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-6-1.png" width="768" /></p>
<pre class="r"><code>     # xlim=c( min( cp@output$WAIC - cp@output$SE) , 
    #          max(cp@output$WAIC + cp@output$SE ) ) )</code></pre>
<p>Note also that the difference has a small standard error, so the order of the models wouldn’t easily change.</p>
<p>Let’s have a look at the third model to understand why it performs poorly compared with the second one:</p>
<pre class="r"><code>precis(m10.3)</code></pre>
<pre><code>           mean        sd       5.5%     94.5%
a    0.04770348 0.1260040 -0.1536753 0.2490822
bp   0.60971850 0.2261470  0.2482919 0.9711451
bpC -0.10398939 0.2635913 -0.5252592 0.3172804</code></pre>
<pre class="r"><code>plot( precis(m10.3) )</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-8-1.png" width="768" /></p>
<p>The interaction variable has a rather wide posterior.
Let’s have a closer look at the parameter <code>bp</code> for the effect of the prosocial option. We have to distinguish between the absolute and relative effect.</p>
<p>Changing the predictor <code>prosoc_left</code> from 0 to 1 increases the log-odds of pulling the left-hand lever by 0.61. This implies the odds are multiplied by:</p>
<pre class="r"><code>exp(0.61)</code></pre>
<pre><code>[1] 1.840431</code></pre>
<p>That is, the odds increase by 84%. This is the relative effect. The relative effect depend strongly on the other parameter als well. If we assume for example an <span class="math inline">\(\alpha\)</span> value of 4 then the probability for a pull, ignoring everything else:</p>
<pre class="r"><code>logistic(4)</code></pre>
<pre><code>[1] 0.9820138</code></pre>
<p>is already quite high. Adding then the increase of 0.61 (relative increase of 84%) changes this to</p>
<pre class="r"><code>logistic(4 + 0.61)</code></pre>
<pre><code>[1] 0.9901462</code></pre>
<p>In this example, the absolute effect would thus be small.</p>
<p>Let’s plot the absolute effect:</p>
<pre class="r"><code># dummy data for predictions across treatments
d.pred &lt;- data.frame(
  prosoc_left = c(0, 1, 0, 1), # right/left/right/left
  condition = c(0, 0, 1, 1)    # control/control/partner/partner
)

# build prediction ensemble
chimp.ensemble &lt;- ensemble(m10.1, m10.2, m10.3, data=d.pred)

# summarize
pred.p &lt;- apply(chimp.ensemble$link, 2, mean)
pred.p.PI &lt;- apply(chimp.ensemble$link, 2, PI)</code></pre>
<pre class="r"><code>plot( 0, 0, type=&quot;n&quot;, xlab=&quot;prosoc_left/condition&quot;,
      ylab=&quot;proportion pulled left&quot;,
      ylim=c(0,1), xaxt=&quot;n&quot;, xlim=c(1,4) )
axis(1, at=1:4, labels=c(&quot;0/0&quot;, &quot;1/0&quot;, &quot;0/1&quot;, &quot;1/1&quot;))

p &lt;- by( d$pulled_left,
    list(d$prosoc_left, d$condition, d$actor ), mean)

for ( chimp in 1:7) 
  lines( 1:4, as.vector(p[,,chimp]),
         col=&quot;royalblue4&quot;, lwd=1.5)

lines( 1:4, pred.p )
shade(pred.p.PI, 1:4)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-13-1.png" width="480" /></p>
<p>Compare the MAP model with a MCMC Stan model:</p>
<pre class="r"><code># clean NAs from the data
d2 &lt;- d
d2$recipient &lt;- NULL

# re-use map fit to get the formula
m10.3stan &lt;- map2stan(m10.3, data=d2, iter=1e4, warmup=1000 )
precis(m10.3stan)</code></pre>
<pre class="r"><code>precis(m10.3stan)</code></pre>
<pre><code>           mean        sd       5.5%     94.5%    n_eff     Rhat4
a    0.05063956 0.1253442 -0.1466587 0.2535746 4832.785 1.0000571
bp   0.60909241 0.2253974  0.2525596 0.9732595 4171.547 0.9999050
bpC -0.10152022 0.2665539 -0.5258567 0.3245502 4393.468 0.9998918</code></pre>
<p>The numbers are almost identical with the MAP model and we can check the pairs plot to see that the posterior is indeed well approximated by a quadratic.</p>
<pre class="r"><code>pairs(m10.3stan)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>We saw in the plot of the average proportions pulled left above that some chimpanzees have a preference for pulling the left or right lever. One even always pulled the left lever. A factor here might be the handedness of the chimp.
One thing we can do, is to fit an intercept for each individula:
<span class="math display">\[\begin{align*}
L_i &amp;\sim \text{Binomial}(1, p_i)\\
\text{logit}(p_i) &amp;= \alpha_{\text{ACTOR}[i]} + (\beta_P + \beta_{PC}C_i)P_i \\
\alpha &amp;\sim \text{Normal}(0, 10) \\
\beta_P &amp;\sim \text{Normal}(0, 10) \\
\beta_{PC} &amp;\sim \text{Normal}(0, 10) 
\end{align*}\]</span>
We fit this with MCMC since it will turn out to have some skew in its posterior distribution.</p>
<pre class="r"><code>m10.4 &lt;- map2stan(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) &lt;- a[actor] + (bp + bpC*condition)*prosoc_left,
    a[actor] ~ dnorm(0, 10),
    bp ~ dnorm(0, 10),
    bpC ~ dnorm(0, 10)
  ),
  data=d2, chains=2, iter=2500, warmup=500
)</code></pre>
<p>Number of actors:</p>
<pre class="r"><code>unique(d$actor)</code></pre>
<pre><code>[1] 1 2 3 4 5 6 7</code></pre>
<pre class="r"><code>precis(m10.4, depth=2)</code></pre>
<pre><code>           mean        sd       5.5%      94.5%    n_eff     Rhat4
a[1] -0.7430094 0.2722710 -1.1844461 -0.3065746 3644.481 1.0008288
a[2] 11.1110158 5.4369195  4.6743364 21.4631269 1977.246 1.0011757
a[3] -1.0587065 0.2829557 -1.5276684 -0.6243400 3703.506 0.9998681
a[4] -1.0549979 0.2851375 -1.5194521 -0.5949534 2992.954 1.0020444
a[5] -0.7478554 0.2728858 -1.1811437 -0.3123281 4198.502 1.0005778
a[6]  0.2113113 0.2676306 -0.2210728  0.6336893 3698.776 1.0003385
a[7]  1.8031784 0.3991891  1.1990170  2.4707487 4511.980 1.0002131
bp    0.8436144 0.2648247  0.4153247  1.2656743 2197.847 1.0010277
bpC  -0.1373488 0.2960272 -0.6124452  0.3296532 2742.691 1.0005659</code></pre>
<p>This posterior is not entirely Gaussian:</p>
<pre class="r"><code>post &lt;- extract.samples( m10.4)
str(post)</code></pre>
<pre><code>List of 3
 $ a  : num [1:4000, 1:7] -0.801 -0.7 -0.812 -0.565 -0.657 ...
 $ bp : num [1:4000(1d)] 0.489 0.998 0.987 0.667 1.308 ...
 $ bpC: num [1:4000(1d)] -0.00164 -0.42957 -0.11204 -0.34127 -0.23503 ...</code></pre>
<pre class="r"><code>dens(post$a[,2])</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Plotting the predictions for each actor:</p>
<pre class="r"><code>par(mfrow=c(4, 2))
for (chimp in 1:7) {
  d.pred &lt;- list(
    pulled_left = rep(0, 4),       # empty outcomes
    prosoc_left = c(0, 1, 0, 1),   # right/left/right/left
    condition = c(0, 0, 1, 1),     # control/control/partner/partner
    actor = rep(chimp, 4)
  )
  link.m10.4 &lt;- link( m10.4, data=d.pred)
  pred.p &lt;- apply( link.m10.4, 2, mean)
  pred.p.PI &lt;- apply( link.m10.4, 2, PI )
  
  plot(0, 0, type=&quot;n&quot;, xlab=&quot;prosoc_left/condition&quot;,
       ylab=&quot;proportion pulled left&quot;,
       ylim=c(0,1), xaxt=&quot;n&quot;,
       xlim=c(1, 4), yaxp=c(0,1,2) )
  axis(1, at=1:4, labels=c(&quot;0/0&quot;, &quot;1/0&quot;, &quot;0/1&quot;, &quot;1/1&quot;))
  mtext(paste( &quot;actor&quot;, chimp ))
  
  p &lt;- by( d$pulled_left,
           list(d$prosoc_left, d$condition, d$actor), mean )
  lines( 1:4, as.vector(p[,,chimp]), col=&quot;royalblue4&quot;, lwd=2)
  
  lines(1:4, pred.p)
  shade(pred.p.PI, 1:4)
}</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-22-1.png" width="768" /></p>
</div>
<div id="aggregated-binomial" class="section level2">
<h2>Aggregated binomial</h2>
<div id="chimpanzees" class="section level3">
<h3>Chimpanzees</h3>
<p>Instead of predicting the likelihood for a single pull (0 or 1), we can also predict the counts, i.e. how likely is it that an actor pulls left <code>x</code> times out of 18 trials.</p>
<pre class="r"><code>data(chimpanzees)
d &lt;- chimpanzees
d.aggregated &lt;- aggregate( d$pulled_left,
                           list(prosoc_left=d$prosoc_left,
                                condition=d$condition,
                                actor=d$actor),
                           sum)
knitr::kable( head(d.aggregated,  8) )</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">prosoc_left</th>
<th align="right">condition</th>
<th align="right">actor</th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">9</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">5</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">18</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">18</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">18</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">18</td>
</tr>
</tbody>
</table>
<pre class="r"><code>m10.5 &lt;- map(
  alist(
    x ~ dbinom( 18, p ),
    logit(p) &lt;- a + (bp + bpC*condition)*prosoc_left,
    a ~ dnorm(0, 10),
    bp ~ dnorm(0, 10),
    bpC ~ dnorm(0, 10)
  ),
  data = d.aggregated
)
precis(m10.5)</code></pre>
<pre><code>           mean        sd       5.5%     94.5%
a    0.04771759 0.1260040 -0.1536612 0.2490964
bp   0.60966987 0.2261462  0.2482446 0.9710951
bpC -0.10396505 0.2635904 -0.5252334 0.3173033</code></pre>
<p>Compare with the same model with non-aggregated data:</p>
<pre class="r"><code>precis(m10.3stan)</code></pre>
<pre><code>           mean        sd       5.5%     94.5%    n_eff     Rhat4
a    0.05063956 0.1253442 -0.1466587 0.2535746 4832.785 1.0000571
bp   0.60909241 0.2253974  0.2525596 0.9732595 4171.547 0.9999050
bpC -0.10152022 0.2665539 -0.5258567 0.3245502 4393.468 0.9998918</code></pre>
<p>We get the same estimates.</p>
</div>
<div id="graduate-school-admissions" class="section level3">
<h3>Graduate school admissions</h3>
<pre class="r"><code>data(&quot;UCBadmit&quot;)
d &lt;- UCBadmit
knitr::kable(d)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">dept</th>
<th align="left">applicant.gender</th>
<th align="right">admit</th>
<th align="right">reject</th>
<th align="right">applications</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A</td>
<td align="left">male</td>
<td align="right">512</td>
<td align="right">313</td>
<td align="right">825</td>
</tr>
<tr class="even">
<td align="left">A</td>
<td align="left">female</td>
<td align="right">89</td>
<td align="right">19</td>
<td align="right">108</td>
</tr>
<tr class="odd">
<td align="left">B</td>
<td align="left">male</td>
<td align="right">353</td>
<td align="right">207</td>
<td align="right">560</td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left">female</td>
<td align="right">17</td>
<td align="right">8</td>
<td align="right">25</td>
</tr>
<tr class="odd">
<td align="left">C</td>
<td align="left">male</td>
<td align="right">120</td>
<td align="right">205</td>
<td align="right">325</td>
</tr>
<tr class="even">
<td align="left">C</td>
<td align="left">female</td>
<td align="right">202</td>
<td align="right">391</td>
<td align="right">593</td>
</tr>
<tr class="odd">
<td align="left">D</td>
<td align="left">male</td>
<td align="right">138</td>
<td align="right">279</td>
<td align="right">417</td>
</tr>
<tr class="even">
<td align="left">D</td>
<td align="left">female</td>
<td align="right">131</td>
<td align="right">244</td>
<td align="right">375</td>
</tr>
<tr class="odd">
<td align="left">E</td>
<td align="left">male</td>
<td align="right">53</td>
<td align="right">138</td>
<td align="right">191</td>
</tr>
<tr class="even">
<td align="left">E</td>
<td align="left">female</td>
<td align="right">94</td>
<td align="right">299</td>
<td align="right">393</td>
</tr>
<tr class="odd">
<td align="left">F</td>
<td align="left">male</td>
<td align="right">22</td>
<td align="right">351</td>
<td align="right">373</td>
</tr>
<tr class="even">
<td align="left">F</td>
<td align="left">female</td>
<td align="right">24</td>
<td align="right">317</td>
<td align="right">341</td>
</tr>
</tbody>
</table>
<p>The data set contains only 12 rows but since it is aggregated, it actually represents 4526 applications.
The goal is to evaluate whether the data contains evidence for gender bias in admission.</p>
<p>We will fit two models: One using gender as a predictor for <code>admit</code> and one modelling <code>admit</code> as a constant, ignoring gender.</p>
<pre class="r"><code>d$male &lt;- ifelse( d$applicant.gender == &quot;male&quot;, 1, 0 )

m10.6 &lt;- map(
  alist(
    admit ~ dbinom( applications, p ),
    logit(p) &lt;- a + bm*male,
    a ~ dnorm(0, 10),
    bm ~ dnorm(0, 10)
  ),
  data=d
)

m10.7 &lt;- map(
  alist(
    admit ~ dbinom( applications, p),
    logit(p) &lt;- a,
    a ~ dnorm(0, 10)
  ),
  data=d
)</code></pre>
<pre class="r"><code>(cp &lt;- compare( m10.6, m10.7 ) )</code></pre>
<pre><code>           WAIC       SE    dWAIC      dSE     pWAIC       weight
m10.6  984.2015 311.2806  0.00000       NA 102.58582 1.000000e+00
m10.7 1047.7249 314.3372 63.52339 166.2807  85.11608 1.607205e-14</code></pre>
<p>The model using male as a predictor performs better than without. The comparison suggests that gender actually matters a lot:</p>
<pre class="r"><code>plot( cp)# , </code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<pre class="r"><code>     # xlim=c( min( cp@output$WAIC - cp@output$SE) , 
      #        max(cp@output$WAIC + cp@output$SE ) ) )</code></pre>
<p>In which way does it matter?</p>
<pre class="r"><code>precis( m10.6 )</code></pre>
<pre><code>         mean         sd       5.5%      94.5%
a  -0.8304494 0.05077041 -0.9115903 -0.7493085
bm  0.6103062 0.06389095  0.5081962  0.7124163</code></pre>
<p>Being male does improve the chances of being admitted.
The relative difference is <code>exp(0.61) =</code> 1.8404314. This means that a male applicant’s odds are 184% of a female applicant.
Let’s get the absolute scale, which is more important:</p>
<pre class="r"><code>post &lt;- extract.samples( m10.6 )
p.admit.male &lt;- logistic( post$a + post$bm )
p.admit.female &lt;- logistic( post$a )

diff.admit &lt;- p.admit.male - p.admit.female

quantile( diff.admit, c(0.025, 0.5, 0.975 ))</code></pre>
<pre><code>     2.5%       50%     97.5% 
0.1130675 0.1413372 0.1690985 </code></pre>
<p>Thus the median estimate of the male advantage is about 14%.</p>
<pre class="r"><code>dens( diff.admit )</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<pre class="r"><code>postcheck( m10.6, n=1e4 , col=&quot;royalblue4&quot;)

# draw lines connecting points from same dept
for ( i in 1:6 ){
  x &lt;- 1 + 2*(i-1)
  y1 &lt;- d$admit[x]/d$applications[x]       # male
  y2 &lt;- d$admit[x+1]/d$applications[x+1]   # female
  lines( c(x, x+1), c(y1, y2), col=&quot;royalblue4&quot;, lwd=2)
  text(x+0.5, (y1 + y2)/2 + 0.05, d$dept[x], cex=0.8, col=&quot;royalblue4&quot;)
}</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>The first point of a line is the admission rate for males while the second point of a line is the admission rate for females. The expeted predictions are the black open points and the black crosses indicate the 89% interval of the expectations.
The plot shows that only two departments (C and E) and lower admission rates for females.
How come we get such a bad prediction?</p>
<p>The problem: Male and female applicants don’t apply to the same departments and departments have different admission rates. Department A has much higer admission rates than department F and female applicants apply more often to F than to A.</p>
<p>We will build a model that uses a unique intercept per department.</p>
<pre class="r"><code># make index
d$dept_id &lt;- coerce_index( d$dept )

# model with unique intercept for each dept
m10.8 &lt;- map(
  alist(
    admit ~ dbinom( applications, p),
    logit(p) &lt;- a[dept_id],
    a[dept_id] ~ dnorm(0, 10)
  ),
  data=d
)

m10.9 &lt;- map(
  alist(
    admit ~ dbinom( applications, p),
    logit(p) &lt;- a[dept_id] + bm*male,
    a[dept_id] ~ dnorm(0, 10),
    bm ~ dnorm(0, 10)
  ),
  data=d
)</code></pre>
<p>We then compare all three models:</p>
<pre class="r"><code>(cp &lt;- compare( m10.6, m10.7, m10.8, m10.9 ) )</code></pre>
<pre><code>           WAIC        SE      dWAIC        dSE      pWAIC        weight
m10.8  104.9527  17.02849   0.000000         NA   6.434406  9.072928e-01
m10.9  109.5148  15.58673   4.562039   3.796352   9.952036  9.270718e-02
m10.6  998.0261 315.56249 893.073389 326.423590 113.857322 1.069855e-194
m10.7 1044.2402 312.91308 939.287442 324.498596  82.354394 9.864409e-205</code></pre>
<p>As a plot:</p>
<pre class="r"><code>plot( cp )#, </code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<pre class="r"><code>      #xlim=c( min( cp@output$WAIC - cp@output$SE) , 
       #       max(cp@output$WAIC + cp@output$SE ) ) )</code></pre>
<p>The two new models with the unique intercepts perform much better. Now, the model without <code>male</code> is ranked first but the difference between the first two models is tiny. Both models got about half the Akaike weight so you could call it a tie.</p>
<p>So how does gender now affect admission?</p>
<pre class="r"><code>precis( m10.9, depth=2 )</code></pre>
<pre><code>            mean         sd       5.5%       94.5%
a[1]  0.68193888 0.09910200  0.5235548  0.84032302
a[2]  0.63852994 0.11556510  0.4538346  0.82322529
a[3] -0.58062952 0.07465092 -0.6999361 -0.46132294
a[4] -0.61262173 0.08596001 -0.7500024 -0.47524102
a[5] -1.05727066 0.09872297 -1.2150490 -0.89949228
a[6] -2.62392120 0.15766770 -2.8759046 -2.37193777
bm   -0.09992562 0.08083548 -0.2291163  0.02926509</code></pre>
<p>The estimate for <code>bm</code> has changed direction, meaning it now estimates that being male is a disadvantage! The estimate becomes <code>exp(-0.1) =</code> 0.9048374. So a male has about 90% the odds of admission as a female.</p>
<p>Let’s do the posterior check again as before:</p>
<pre class="r"><code>postcheck( m10.9, n=1e4 , col=&quot;royalblue4&quot;)

# draw lines connecting points from same dept
for ( i in 1:6 ){
  x &lt;- 1 + 2*(i-1)
  y1 &lt;- d$admit[x]/d$applications[x]       # male
  y2 &lt;- d$admit[x+1]/d$applications[x+1]   # female
  lines( c(x, x+1), c(y1, y2), col=&quot;royalblue4&quot;, lwd=2)
  text(x+0.5, (y1 + y2)/2 + 0.05, d$dept[x], cex=0.8, col=&quot;royalblue4&quot;)
}</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>The predictions fit much better than before.</p>
<p>Let’s also check the quadratic approximation. In the example with the chimpanzees, unique intercepts were a problem for quadratic approximations, so let’s check how the compare to a Stan model:</p>
<pre class="r"><code>dstan &lt;- d[, c(&quot;admit&quot;, &quot;applications&quot;, &quot;male&quot;, &quot;dept_id&quot;)]
m10.9stan &lt;- map2stan( m10.9, data=dstan,
                       chains=2, iter=2500, warmup=500)
precis(m10.9stan, depth=2)</code></pre>
<pre class="r"><code>pairs(m10.9stan)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-40-1.png" width="864" /></p>
<p>All the posterior distributions are pretty much Gaussian, a quadratic approximation thus gives good estimates.</p>
</div>
</div>
<div id="fitting-binomial-regression-with-glm" class="section level2">
<h2>Fitting binomial regression with <code>glm</code></h2>
<p>The following code yields similar results as the map approach for the aggregated binomial.</p>
<pre class="r"><code>m10.7glm &lt;- glm( cbind( admit, reject) ~ 1, data=d, family=binomial)
m10.6glm &lt;- glm( cbind( admit, reject) ~ male, data=d, family=binomial)
m10.8glm &lt;- glm( cbind( admit, reject) ~ dept, data=d, family=binomial)
m10.9glm &lt;- glm( cbind( admit, reject) ~ male + dept, data=d, 
                 family=binomial )
precis(m10.9glm)</code></pre>
<pre><code>                   mean         sd       5.5%       94.5%
(Intercept)  0.68192148 0.09911270  0.5235203  0.84032272
male        -0.09987009 0.08084647 -0.2290784  0.02933818
deptB       -0.04339793 0.10983890 -0.2189417  0.13214584
deptC       -1.26259802 0.10663289 -1.4330180 -1.09217808
deptD       -1.29460647 0.10582342 -1.4637327 -1.12548020
deptE       -1.73930574 0.12611350 -1.9408595 -1.53775201
deptF       -3.30648006 0.16998181 -3.5781438 -3.03481630</code></pre>
<p>Compare with the <code>map()</code> model:</p>
<pre class="r"><code>precis(m10.9stan, depth=2)</code></pre>
<pre><code>           mean         sd       5.5%       94.5%    n_eff     Rhat4
a[1]  0.6863076 0.09691269  0.5322626  0.83932302 2263.496 0.9999579
a[2]  0.6417298 0.11545820  0.4553979  0.82881994 2360.370 1.0003822
a[3] -0.5808673 0.07352865 -0.7003331 -0.46132209 3235.067 0.9998488
a[4] -0.6104369 0.08724276 -0.7511097 -0.47465331 2591.656 0.9996333
a[5] -1.0607945 0.09930062 -1.2174470 -0.90071297 3168.278 0.9998268
a[6] -2.6314324 0.15796026 -2.8908603 -2.38479805 3238.932 1.0008285
bm   -0.1019495 0.08037660 -0.2306159  0.02743101 1984.762 0.9999576</code></pre>
<p>Note that the departments are coded differently: the intercept in the <code>glm</code> model corresponds to <code>a[1]</code> in the Stan model and <code>deptB</code> in the <code>glm</code> model corresponds to the difference from department A to B, that is <code>a[2]-a[1]</code> in the Stan model.</p>
<p>To use <code>glm()</code> for a non-aggregated model:</p>
<pre class="r"><code>m10.4glm &lt;- glm(
  pulled_left ~ as.factor(actor) + prosoc_left*condition  -condition,
  data=chimpanzees, family=binomial
)
precis(m10.4glm)</code></pre>
<pre><code>                               mean          sd          5.5%        94.5%
(Intercept)           -7.265827e-01   0.2686406    -1.1559223   -0.2972432
as.factor(actor)2      1.894908e+01 754.9798310 -1187.6545076 1225.5526659
as.factor(actor)3     -3.049664e-01   0.3500257    -0.8643751    0.2544423
as.factor(actor)4     -3.049664e-01   0.3500257    -0.8643751    0.2544423
as.factor(actor)5     -2.705907e-15   0.3440353    -0.5498348    0.5498348
as.factor(actor)6      9.395168e-01   0.3489007     0.3819061    1.4971274
as.factor(actor)7      2.483652e+00   0.4506924     1.7633580    3.2039450
prosoc_left            8.223656e-01   0.2613048     0.4047500    1.2399812
prosoc_left:condition -1.323906e-01   0.2971937    -0.6073635    0.3425823</code></pre>
<p>We need to use <code>-condition</code> to remove the main effect of condition.</p>
<p>We can also use <code>glimmer()</code> to get code corresponding to a <code>map</code> or <code>map2stan</code> model.</p>
<pre class="r"><code>glimmer( pulled_left ~ prosoc_left*condition -condition,
         data=chimpanzees, family=binomial)</code></pre>
<pre><code>alist(
    pulled_left ~ dbinom( 1 , p ),
    logit(p) &lt;- Intercept +
        b_prosoc_left*prosoc_left +
        b_prosoc_left_X_condition*prosoc_left_X_condition,
    Intercept ~ dnorm(0,10),
    b_prosoc_left ~ dnorm(0,10),
    b_prosoc_left_X_condition ~ dnorm(0,10)
)</code></pre>
<p>Note that <code>glm</code> uses flat priors by default which can lead to nonsense estimates. Consider for example the following example:</p>
<pre class="r"><code># almost perfectly associated
y &lt;- c( rep(0, 10), rep(1, 10))
x &lt;- c(rep(-1, 9), rep(1, 11))
m.bad &lt;- glm( y ~ x, data=list(x=x, y=y), family=binomial)
precis(m.bad)</code></pre>
<pre><code>                 mean       sd      5.5%    94.5%
(Intercept) -9.131742 2955.062 -4731.891 4713.628
x           11.434327 2955.062 -4711.325 4734.194</code></pre>
<p>The estimates would suggest there is no association between <code>x</code> and <code>y</code> even though there is a strong association. A weak prior helps:</p>
<pre class="r"><code>m.good &lt;- map(
  alist(
    y ~ dbinom(1, p),
    logit(p) &lt;- a + b*x,
    a ~ dnorm(0, 10),
    b ~ dnorm(0, 10)
  ),
  data=list(x=x, y=y)
)
precis(m.good)</code></pre>
<pre><code>       mean       sd       5.5%    94.5%
a -1.726593 2.775005 -6.1615867 2.708401
b  4.016908 2.775005 -0.4180857 8.451902</code></pre>
<p>Since the uncertainty is not symmetric in this case, the quadratic assumption is misleading. Even better would be MCMC samples:</p>
<pre class="r"><code>m.better &lt;- map2stan( m.good)
pairs(m.better)</code></pre>
<p><img src="/projects/Statistical-Rethinking/Chapter_10/chapter10a_files/figure-html/unnamed-chunk-47-1.png" width="576" /></p>
</div>
